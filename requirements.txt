import streamlit as st
from googleapiclient.discovery import build
from collections import Counter
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk

# NLTK ë‹¤ìš´ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ)
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('vader_lexicon')

st.title("ğŸ“º YouTube Live Chat AI ë¶„ì„ê¸°")

# ---------------------------------------------
# YouTube API ì„¤ì •
# ---------------------------------------------
api_key = st.text_input("ğŸ”‘ YouTube API Key ì…ë ¥", type="password")
live_chat_id = st.text_input("ğŸ’¬ Live Chat ID ì…ë ¥")

if st.button("ë¶„ì„ ì‹œì‘"):

    if not api_key or not live_chat_id:
        st.error("API Keyì™€ Live Chat IDë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    youtube = build("youtube", "v3", developerKey=api_key)

    messages = []
    next_page_token = None

    # ---------------------------------------------
    # ë¼ì´ë¸Œ ì±„íŒ… ê°€ì ¸ì˜¤ê¸°
    # ---------------------------------------------
    with st.spinner("ë¼ì´ë¸Œ ì±„íŒ… ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        for _ in range(3):  # ì—¬ëŸ¬ í˜ì´ì§€ ì½ê¸° (ì›í•˜ë©´ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ)
            chat_response = youtube.liveChatMessages().list(
                liveChatId=live_chat_id,
                part="snippet,authorDetails",
                pageToken=next_page_token
            ).execute()

            for item in chat_response["items"]:
                messages.append(item["snippet"]["displayMessage"])

            next_page_token = chat_response.get("nextPageToken")
            if not next_page_token:
                break

    if not messages:
        st.warning("ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        st.stop()

    st.success(f"ì´ {len(messages)}ê°œì˜ ì±„íŒ… ë©”ì‹œì§€ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    st.write(messages[:10])  # ì¼ë¶€ ë¯¸ë¦¬ë³´ê¸°

    # ---------------------------------------------
    # í…ìŠ¤íŠ¸ ì •ì œ + í† í°í™”
    # ---------------------------------------------
    stop_words = set(stopwords.words("english") | stopwords.words("korean"))
    cleaned_words = []

    for msg in messages:
        msg = msg.lower()
        msg = re.sub(r"[^a-zA-Zê°€-í£0-9\s]", "", msg)
        words = word_tokenize(msg)
        words = [w for w in words if w not in stop_words and len(w) > 1]
        cleaned_words.extend(words)

    # ---------------------------------------------
    # 1) ì–´ë–¤ ë‹¨ì–´ê°€ ë§ì´ ë‚˜ì™”ëŠ”ê°€?
    # ---------------------------------------------
    word_freq = Counter(cleaned_words)
    df_words = pd.DataFrame(word_freq.most_common(20), columns=["ë‹¨ì–´", "íšŸìˆ˜"])
    st.subheader("ğŸ“Œ ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‹¨ì–´ TOP 20")
    st.bar_chart(df_words.set_index("ë‹¨ì–´"))

    # ---------------------------------------------
    # 2) ì–´ë–¤ ì£¼ì œì˜ ëŒ€í™”ì¸ê°€? (ê°„ë‹¨í•œ keyword ê¸°ë°˜ Topic)
    # ---------------------------------------------
    topics = {
        "AI / ê¸°ìˆ ": ["ai", "robot", "machine", "tech", "chatgpt", "api"],
        "ê²Œì„": ["game", "fps", "lol", "valorant", "minecraft"],
        "ì •ì¹˜": ["president", "election", "government"],
        "ìŠ¤í¬ì¸ ": ["sports", "soccer", "basketball", "football"],
        "ìŒì•…": ["music", "song", "kpop", "idol"],
    }

    topic_scores = {k: 0 for k in topics}

    for w in cleaned_words:
        for topic, keywords in topics.items():
            if w in keywords:
                topic_scores[topic] += 1

    topic_df = pd.DataFrame(topic_scores.items(), columns=["ì£¼ì œ", "ê´€ë ¨ ë‹¨ì–´ ìˆ˜"])

    st.subheader("ğŸ“Œ ì±„íŒ… ì£¼ìš” í† í”½ ì¶”ì •")
    st.bar_chart(topic_df.set_index("ì£¼ì œ"))

    # ---------------------------------------------
    # 3) ì–´ë–¤ ì˜ê²¬ì´ ì œì¼ ë§ì€ê°€? (ê°ì„± ë¶„ì„)
    # ---------------------------------------------
    sia = SentimentIntensityAnalyzer()

    sentiments = {"ê¸ì •": 0, "ì¤‘ë¦½": 0, "ë¶€ì •": 0}

    for msg in messages:
        score = sia.polarity_scores(msg)
        if score["compound"] > 0.2:
            sentiments["ê¸ì •"] += 1
        elif score["compound"] < -0.2:
            sentiments["ë¶€ì •"] += 1
        else:
            sentiments["ì¤‘ë¦½"] += 1

    sentiment_df = pd.DataFrame(sentiments.items(), columns=["ê°ì •", "ê°œìˆ˜"])

    st.subheader("ğŸ“Œ ì±„íŒ… ì˜ê²¬ ê°ì„± ë¶„ì„ ê²°ê³¼")
    st.bar_chart(sentiment_df.set_index("ê°ì •"))
